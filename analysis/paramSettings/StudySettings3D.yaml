# This is an example of settings that can be used as a starting point for analyzing MR data with small (~3mm) slice
# thickness. This is only intended as a starting point and is not likely to be the optimal settings for your dataset.
# Some points in determining better values are added as comments where appropriate

# When adapting and using these settings for an analysis, be sure to add the PyRadiomics version used to allow you to
# easily recreate your extraction at a later timepoint:

# #############################  Extracted using PyRadiomics version: <version>  ######################################

imageType:
  Original: {}
  LoG:
    # If you include sigma values >5, remember to also increase the padDistance. Because of resampling to (2, 2, 2), the
    # use of sigmas < 2 mm is not recommended.
    sigma: [2.0, 3.0, 4.0, 5.0]
  Wavelet: {}
  Square: {}
  SquareRoot: {}
  Logarithm: {}
  Exponential: {}
  Gradient: {}
  LBP3D: {}

featureClass:

  shape: 
    - 'Elongation'
    - 'Flatness'
    - 'LeastAxisLength'
    - 'MajorAxisLength'
    - 'Maximum2DDiameterColumn'
    - 'Maximum2DDiameterRow'
    - 'Maximum2DDiameterSlice'
    - 'Maximum3DDiameter'
    - 'MeshVolume'
    - 'MinorAxisLength'
    - 'Sphericity' 
    - 'SurfaceArea'
    - 'SurfaceVolumeRatio'
    - 'VoxelVolume'

  firstorder: 
    - '10Percentile'
    - '90Percentile'
    - 'Energy'
    - 'Entropy'
    - 'InterquartileRange'
    - 'Kurtosis'
    - 'Maximum'
    - 'MeanAbsoluteDeviation'
    - 'Mean'
    - 'Median'
    - 'Minimum'
    - 'Range'
    - 'RobustMeanAbsoluteDeviation'
    - 'RootMeanSquared'
    - 'Skewness'
    - 'Variance'
    - 'Uniformity'
    
  glcm:  
    - 'Autocorrelation'
    - 'ClusterProminence'
    - 'ClusterShade'
    - 'ClusterTendency'
    - 'Contrast'
    - 'Correlation'
    - 'DifferenceAverage'
    - 'DifferenceEntropy'
    - 'DifferenceVariance'
    - 'Id'
    - 'Idm'
    - 'Idmn'
    - 'Idn'
    - 'Imc1'
    - 'Imc2'
    - 'InverseVariance'
    - 'JointAverage'
    - 'JointEnergy'
    - 'JointEntropy'
    - 'MCC'
    - 'MaximumProbability'
    - 'SumEntropy'
    - 'SumSquares'
    
  glrlm:
  glszm:
  ngtdm:
  gldm:
   - 'DependenceEntropy'
   - 'DependenceNonUniformity'
   - 'DependenceNonUniformityNormalized'
   - 'DependenceVariance'
   - 'GrayLevelNonUniformity'
   - 'GrayLevelVariance'
   - 'HighGrayLevelEmphasis'
   - 'LargeDependenceEmphasis'
   - 'LargeDependenceHighGrayLevelEmphasis'
   - 'LargeDependenceLowGrayLevelEmphasis'
   - 'LowGrayLevelEmphasis'
   - 'SmallDependenceEmphasis'
   - 'SmallDependenceHighGrayLevelEmphasis'
   - 'SmallDependenceLowGrayLevelEmphasis'
    
    
  # GLDM: Total 16 features; Excluded DependencePercentage (deprecated) and 
  # GrayLevelNonUniformityNormalized (mathematically equal to First Order - Uniformity)
  
  # GLCM: Disable SumAverage by specifying all other GLCM features available
  # Total 28 features; Excluded Dissimilarity (mathematically equal to Difference Average), 
  # Homogeneity 1 (equal to Id) and 2 (equal to Idm) , and Sum Variance (equal to cluster tendency)
  # Sum Average = 2 * Joint Average, only 1 needs to be calculated
  
  # Firstorder: Total 19 features; Excluded StandardDeviation (feature is correlated with variance) and 
  # Total Energy (Not present in IBSI feature definitions)
  
  # Shape: # Total feats - 17; Excluded compactness1, 2 and spherical disproportion as it is correlated to Sphericity
  
  

setting:
  # Normalization:
  # MR signal is usually relative, with large differences between scanners and vendors. By normalizing the image before
  # feature calculation, this confounding effect may be reduced. However, if only one specific scanner is used, or the
  # images reflect some absolute world value (e.g. ADC maps, T2maps (NOT T2 weighted)), consider disabling the
  # normalization. will be done before feeding the image to the model
  # normalize: True
  # normalizeScale: 100  # This allows you to use more or less the same bin width.

  # Resampling:
  # If slices are very thin (~1mm), such as in 3D scanned (isotropic) volumes, resampledPixelSpacing may be reduced to
  # (1, 1, 1). Furthermore, in case of isotropic volumes, consider disabling resampling.
  # On a side note: increasing the resampled spacing forces PyRadiomics to look at more coarse textures, which may or
  # may not increase accuracy and stability of your extracted features.
  interpolator: 'sitkBSpline'
  resampledPixelSpacing: [2, 2, 2]

  # Mask validation:
  # correctMask and geometryTolerance are not needed, as both image and mask are resampled, if you expect very small
  # masks, consider to enable a size constraint by uncommenting settings below:
  #minimumROIDimensions: 2
  #minimumROISize: 50

  # Image discretization:
  # The ideal number of bins is somewhere in the order of 16-128 bins. A possible way to define a good binwidt is to
  # extract firstorder:Range from the dataset to analyze, and choose a binwidth so, that range/binwidth remains approximately
  # in this range of bins.
  binCount: 32

  # first order specific settings:
  # When normalizing, gray values below the mean will be negative. Shifting by 300 (3 StdDevs * 100) ensures that the
  # majority of voxels is positive (only outliers >3 SD lower than the mean will be negative).
  # voxelArrayShift = 0; because in IBSI definition; no correction for negative gray values is implemented
  # voxelArrayShift: 0 

  # Misc:
  # default label value. Labels can also be defined in the call to featureextractor.execute, as a commandline argument,
  # or in a column "Label" in the input csv (batchprocessing)
  label: 1
  
  preCrop: True
  padDistance: 11
  
  # voxelSetting:
      #   kernelRadius: 2
      #   maskedKernel: true
      #   initValue: 0
      #   voxelBatch: 1000
      
   
